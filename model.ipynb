{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jwu8e7TcvIA",
    "outputId": "fea28a66-1437-4c60-f53c-a951c3e20046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'dogs', 'horses', 'humans']\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "parent_dir = \"./dataset/\"\n",
    "folders = os.listdir(parent_dir + \"/multiclass\") # Path to Training Images\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUO-QLR4dFXq"
   },
   "source": [
    "## Separating Training data from Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TmAz8QeFcu-a"
   },
   "outputs": [],
   "source": [
    "def separate():\n",
    "    for each_class in classes: # Iterate over each class\n",
    "        image_path = os.path.join(parent_dir + \"val_images\", each_class)# creating a seperate folder for each class in validation folder\n",
    "        \n",
    "        if not image_path:\n",
    "            os.mkdir(image_path)\n",
    "\n",
    "        SPLIT = 0.9 # spliting data into 90:10 \n",
    "\n",
    "        # Load all images from training data and make a split\n",
    "        for image_folder in os.listdir(parent_dir + \"/multiclass\"):\n",
    "            Path = parent_dir + \"/multiclass/\" + image_folder\n",
    "            images = os.listdir(Path)# Load all the images\n",
    "            split_size =  int(SPLIT * len(images))\n",
    "            images_to_move = images[split_size :] # Train-Test split\n",
    "          #print(len(images_to_move))\n",
    "            for validation_image in images_to_move:\n",
    "                src = os.path.join(Path, validation_image) \n",
    "                dest = os.path.join(parent_dir + \"/val_images/\" + image_folder, validation_image)\n",
    "                shutil.move(src, dest) # Moving selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O9Gr7ymMcvB0"
   },
   "outputs": [],
   "source": [
    "def create_folders():\n",
    "    classes = [\"dogs\", \"cats\", \"horses\", \"humans\"] # Labels\n",
    "    \n",
    "    # If the separation already exists\n",
    "    if os.path.isdir(parent_dir + \"/val_images\"):\n",
    "        print(\"Separation has been done already! \")\n",
    "        return\n",
    "    \n",
    "    # If not create a validation folder\n",
    "    else:\n",
    "        os.mkdir(parent_dir + \"/val_images\")\n",
    "\n",
    "    # Now create a seperate folder for each label\n",
    "    for label in classes:\n",
    "        os.mkdir(parent_dir + \"/val_images/\" + label)\n",
    "    separate()\n",
    "    print(\"Separation done successfully!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separation has been done already! \n"
     ]
    }
   ],
   "source": [
    "create_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1XZf1xPsA2B"
   },
   "source": [
    "### ```Now how many images left in training dataset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJs4isPWnmXM",
    "outputId": "fe45c435-b03b-478f-82d4-8f7fed72371b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats 181\n",
      "dogs 181\n",
      "horses 181\n",
      "humans 181\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    Path = parent_dir + \"/multiclass/\" + folder\n",
    "    print(folder + \" \" + str(len(os.listdir(Path))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycogzgZJsOJo"
   },
   "source": [
    "### ```And what about validation dataset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVJGH6Q5nmPn",
    "outputId": "caf6645f-454c-4d8e-b19e-c49071e5afdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats 21\n",
      "dogs 21\n",
      "horses 21\n",
      "humans 21\n"
     ]
    }
   ],
   "source": [
    "validation_folder = os.listdir(parent_dir + \"/val_images/\")\n",
    "for folder in validation_folder:\n",
    "    Path = parent_dir + \"/val_images/\" + folder\n",
    "    print(folder + \" \" + str(len(os.listdir(Path))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xl86lqZ8vY0X"
   },
   "source": [
    "### ``` Train data generator```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZnCcf81Ku5HX"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Training Data Generator```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "V_zszdj9u5Ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 724 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                               rotation_range = 40,\n",
    "                               width_shift_range = 0.2,\n",
    "                               height_shift_range = 0.2,\n",
    "                               shear_range = 0.2,\n",
    "                               zoom_range = 0.3,\n",
    "                               horizontal_flip = True)\n",
    "\n",
    "train_generator = train_gen.flow_from_directory(parent_dir + \"/multiclass/\",\n",
    "                                                target_size = (300, 300),\n",
    "                                                batch_size = 64,\n",
    "                                                class_mode = \"categorical\"\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJdMhOEou4-b"
   },
   "source": [
    "### ``` Testing Data Generator```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "CbGHOMXtBM7N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_gen = ImageDataGenerator(rescale = 1.0/255)\n",
    "valid_generator = valid_gen.flow_from_directory(parent_dir + \"/val_images/\",\n",
    "                                               target_size = (300, 300),\n",
    "                                               batch_size = 32,\n",
    "                                               class_mode = \"categorical\"\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Lets have a look how train_gen works```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 300, 300, 3)\n",
      "(64, 4)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_generator:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``` Building a CNN Model```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers \n",
    "\n",
    "adam = optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 298, 298, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 149, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 147, 147, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 71, 71, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 35, 35, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 33, 33, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                2097216   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,338,308\n",
      "Trainable params: 2,338,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = \"relu\", input_shape = (300, 300, 3)))\n",
    "model.add(MaxPool2D(2, 2))\n",
    "model.add(Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPool2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPool2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPool2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(4, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      " 2/12 [====>.........................] - ETA: 1s - loss: 1.3855 - accuracy: 0.2344WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1117s vs `on_train_batch_end` time: 0.2244s). Check your callbacks.\n",
      "12/12 [==============================] - 11s 902ms/step - loss: 1.3921 - accuracy: 0.2486 - val_loss: 1.3763 - val_accuracy: 0.2500\n",
      "Epoch 2/80\n",
      "12/12 [==============================] - 12s 989ms/step - loss: 1.3785 - accuracy: 0.2914 - val_loss: 1.3565 - val_accuracy: 0.3571\n",
      "Epoch 3/80\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.3590 - accuracy: 0.3191 - val_loss: 1.3222 - val_accuracy: 0.2857\n",
      "Epoch 4/80\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.3214 - accuracy: 0.3909 - val_loss: 1.2528 - val_accuracy: 0.4286\n",
      "Epoch 5/80\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.2593 - accuracy: 0.4406 - val_loss: 1.2178 - val_accuracy: 0.4524\n",
      "Epoch 6/80\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.2001 - accuracy: 0.4751 - val_loss: 1.1768 - val_accuracy: 0.5000\n",
      "Epoch 7/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.1861 - accuracy: 0.4779 - val_loss: 1.1369 - val_accuracy: 0.5119\n",
      "Epoch 8/80\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.2013 - accuracy: 0.4834 - val_loss: 1.1116 - val_accuracy: 0.5476\n",
      "Epoch 9/80\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.1525 - accuracy: 0.4751 - val_loss: 1.0860 - val_accuracy: 0.5357\n",
      "Epoch 10/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.1296 - accuracy: 0.5014 - val_loss: 1.1361 - val_accuracy: 0.5595\n",
      "Epoch 11/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.1266 - accuracy: 0.5124 - val_loss: 1.1376 - val_accuracy: 0.4881\n",
      "Epoch 12/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.1258 - accuracy: 0.4917 - val_loss: 1.1666 - val_accuracy: 0.5000\n",
      "Epoch 13/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0853 - accuracy: 0.5331 - val_loss: 1.0625 - val_accuracy: 0.5357\n",
      "Epoch 14/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0502 - accuracy: 0.5221 - val_loss: 1.0291 - val_accuracy: 0.5476\n",
      "Epoch 15/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0219 - accuracy: 0.5677 - val_loss: 1.0037 - val_accuracy: 0.5595\n",
      "Epoch 16/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0300 - accuracy: 0.5373 - val_loss: 1.0286 - val_accuracy: 0.5714\n",
      "Epoch 17/80\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.9892 - accuracy: 0.5746 - val_loss: 0.9636 - val_accuracy: 0.5833\n",
      "Epoch 18/80\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.9950 - accuracy: 0.5801 - val_loss: 0.9226 - val_accuracy: 0.5952\n",
      "Epoch 19/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.9560 - accuracy: 0.6050 - val_loss: 0.9356 - val_accuracy: 0.6071\n",
      "Epoch 20/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0042 - accuracy: 0.5787 - val_loss: 1.0633 - val_accuracy: 0.5595\n",
      "Epoch 21/80\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9707 - accuracy: 0.5732 - val_loss: 0.9132 - val_accuracy: 0.6071\n",
      "Epoch 22/80\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.9449 - accuracy: 0.6064 - val_loss: 0.8659 - val_accuracy: 0.6190\n",
      "Epoch 23/80\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.9319 - accuracy: 0.5967 - val_loss: 0.8671 - val_accuracy: 0.6429\n",
      "Epoch 24/80\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.9281 - accuracy: 0.6133 - val_loss: 0.8561 - val_accuracy: 0.6429\n",
      "Epoch 25/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.9087 - accuracy: 0.6146 - val_loss: 0.8631 - val_accuracy: 0.6429\n",
      "Epoch 26/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.9315 - accuracy: 0.5953 - val_loss: 0.8822 - val_accuracy: 0.6310\n",
      "Epoch 27/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.9179 - accuracy: 0.6340 - val_loss: 0.8361 - val_accuracy: 0.6667\n",
      "Epoch 28/80\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.8775 - accuracy: 0.6409 - val_loss: 0.8257 - val_accuracy: 0.6548\n",
      "Epoch 29/80\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8547 - accuracy: 0.6436 - val_loss: 0.8565 - val_accuracy: 0.6310\n",
      "Epoch 30/80\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8733 - accuracy: 0.6492 - val_loss: 0.8021 - val_accuracy: 0.7143\n",
      "Epoch 31/80\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.8670 - accuracy: 0.6533 - val_loss: 0.8281 - val_accuracy: 0.6786\n",
      "Epoch 32/80\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.8296 - accuracy: 0.6450 - val_loss: 0.7932 - val_accuracy: 0.6786\n",
      "Epoch 33/80\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.8273 - accuracy: 0.6630 - val_loss: 0.7991 - val_accuracy: 0.7024\n",
      "Epoch 34/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.8213 - accuracy: 0.6644 - val_loss: 0.8481 - val_accuracy: 0.6429\n",
      "Epoch 35/80\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.8146 - accuracy: 0.6492 - val_loss: 0.7926 - val_accuracy: 0.6786\n",
      "Epoch 36/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.8574 - accuracy: 0.6547 - val_loss: 0.8791 - val_accuracy: 0.6667\n",
      "Epoch 37/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.8535 - accuracy: 0.6395 - val_loss: 0.9021 - val_accuracy: 0.6429\n",
      "Epoch 38/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.8395 - accuracy: 0.6506 - val_loss: 0.7785 - val_accuracy: 0.7143\n",
      "Epoch 39/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.7910 - accuracy: 0.6754 - val_loss: 0.7326 - val_accuracy: 0.6905\n",
      "Epoch 40/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.8184 - accuracy: 0.6533 - val_loss: 0.7605 - val_accuracy: 0.6905\n",
      "Epoch 41/80\n",
      "12/12 [==============================] - 18s 1s/step - loss: 0.8049 - accuracy: 0.6602 - val_loss: 0.7304 - val_accuracy: 0.7143\n",
      "Epoch 42/80\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7712 - accuracy: 0.6878 - val_loss: 0.7737 - val_accuracy: 0.6667\n",
      "Epoch 43/80\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7642 - accuracy: 0.6837 - val_loss: 0.7228 - val_accuracy: 0.7262\n",
      "Epoch 44/80\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7724 - accuracy: 0.6878 - val_loss: 0.7917 - val_accuracy: 0.7024\n",
      "Epoch 45/80\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.8355 - accuracy: 0.6547 - val_loss: 0.7659 - val_accuracy: 0.6786\n",
      "Epoch 46/80\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8013 - accuracy: 0.6782 - val_loss: 0.7870 - val_accuracy: 0.7024\n",
      "Epoch 47/80\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8057 - accuracy: 0.6588 - val_loss: 0.7368 - val_accuracy: 0.7381\n",
      "Epoch 48/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.7862 - accuracy: 0.6630 - val_loss: 0.7439 - val_accuracy: 0.7024\n",
      "Epoch 49/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.7744 - accuracy: 0.6837 - val_loss: 0.7088 - val_accuracy: 0.7262\n",
      "Epoch 50/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.7524 - accuracy: 0.6920 - val_loss: 0.7352 - val_accuracy: 0.7024\n",
      "Epoch 51/80\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.7147 - accuracy: 0.7224 - val_loss: 0.7194 - val_accuracy: 0.7024\n",
      "Epoch 52/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.7818 - accuracy: 0.6809 - val_loss: 0.7307 - val_accuracy: 0.7381\n",
      "Epoch 53/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.7504 - accuracy: 0.6740 - val_loss: 0.7188 - val_accuracy: 0.7143\n",
      "Epoch 54/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.7415 - accuracy: 0.6823 - val_loss: 0.7203 - val_accuracy: 0.7262\n",
      "Epoch 55/80\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.7324 - accuracy: 0.7044 - val_loss: 0.7326 - val_accuracy: 0.6667\n",
      "Epoch 56/80\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7135 - accuracy: 0.7003 - val_loss: 0.7459 - val_accuracy: 0.6786\n",
      "Epoch 57/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 0.6952 - accuracy: 0.7293 - val_loss: 0.7104 - val_accuracy: 0.6905\n",
      "Epoch 58/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.7246 - accuracy: 0.6809 - val_loss: 0.7318 - val_accuracy: 0.7143\n",
      "Epoch 59/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.6925 - accuracy: 0.7182 - val_loss: 0.7475 - val_accuracy: 0.6905\n",
      "Epoch 60/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.6933 - accuracy: 0.7141 - val_loss: 0.7806 - val_accuracy: 0.7262\n",
      "Epoch 61/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.7001 - accuracy: 0.7155 - val_loss: 0.6835 - val_accuracy: 0.7143\n",
      "Epoch 62/80\n",
      "12/12 [==============================] - 18s 1s/step - loss: 0.6992 - accuracy: 0.7182 - val_loss: 0.7996 - val_accuracy: 0.7143\n",
      "Epoch 63/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.7029 - accuracy: 0.7320 - val_loss: 0.7277 - val_accuracy: 0.6905\n",
      "Epoch 64/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.6869 - accuracy: 0.7210 - val_loss: 0.6865 - val_accuracy: 0.7024\n",
      "Epoch 65/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.7177 - accuracy: 0.7238 - val_loss: 0.6569 - val_accuracy: 0.7381\n",
      "Epoch 66/80\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.7529 - accuracy: 0.6796 - val_loss: 0.7106 - val_accuracy: 0.6786\n",
      "Epoch 67/80\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7134 - accuracy: 0.7113 - val_loss: 0.6739 - val_accuracy: 0.7024\n",
      "Epoch 68/80\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6618 - accuracy: 0.7182 - val_loss: 0.7201 - val_accuracy: 0.7262\n",
      "Epoch 69/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.6614 - accuracy: 0.7376 - val_loss: 0.7155 - val_accuracy: 0.6786\n",
      "Epoch 70/80\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.6708 - accuracy: 0.7431 - val_loss: 0.7186 - val_accuracy: 0.6667\n",
      "Epoch 71/80\n",
      "12/12 [==============================] - 18s 1s/step - loss: 0.6758 - accuracy: 0.7182 - val_loss: 0.7079 - val_accuracy: 0.7024\n",
      "Epoch 72/80\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.6497 - accuracy: 0.7320 - val_loss: 0.7095 - val_accuracy: 0.7143\n",
      "Epoch 73/80\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6561 - accuracy: 0.7307 - val_loss: 0.6862 - val_accuracy: 0.7024\n",
      "Epoch 74/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.6770 - accuracy: 0.7141 - val_loss: 0.6847 - val_accuracy: 0.7024\n",
      "Epoch 75/80\n",
      "12/12 [==============================] - 18s 1s/step - loss: 0.6465 - accuracy: 0.7403 - val_loss: 0.7339 - val_accuracy: 0.6786\n",
      "Epoch 76/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.6484 - accuracy: 0.7307 - val_loss: 0.7120 - val_accuracy: 0.6548\n",
      "Epoch 77/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.6382 - accuracy: 0.7376 - val_loss: 0.7278 - val_accuracy: 0.7024\n",
      "Epoch 78/80\n",
      "12/12 [==============================] - 18s 1s/step - loss: 0.6769 - accuracy: 0.7279 - val_loss: 0.6991 - val_accuracy: 0.7143\n",
      "Epoch 79/80\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.6417 - accuracy: 0.7376 - val_loss: 0.7123 - val_accuracy: 0.7024\n",
      "Epoch 80/80\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.6479 - accuracy: 0.7293 - val_loss: 0.6748 - val_accuracy: 0.7381\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             epochs = 80,\n",
    "                             validation_data = valid_generator,\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
